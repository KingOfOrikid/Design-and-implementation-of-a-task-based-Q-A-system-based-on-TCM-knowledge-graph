{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c996484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for line in open('train_data.txt',encoding='UTF-8'):\n",
    "    line=line.rstrip().split('\\t')\n",
    "    line=line[0].strip().split()\n",
    "    data.append(line)\n",
    "\n",
    "cate=[]\n",
    "for line in open('train_label.txt',encoding='UTF-8'):\n",
    "    line=line.rstrip().split('\\t')\n",
    "    line=line[0].strip().split()\n",
    "    cate.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa5fe858",
   "metadata": {},
   "outputs": [],
   "source": [
    "che=[]\n",
    "dis=[]\n",
    "dru=[]\n",
    "sym=[]\n",
    "\n",
    "for i in range(0,len(cate)):\n",
    "    if 'B-che' in cate[i]:\n",
    "        che.append([data[i],cate[i]])\n",
    "    elif 'B-dis' in cate[i]:\n",
    "        dis.append([data[i],cate[i]])\n",
    "    elif 'B-dru' in cate[i]:\n",
    "        dru.append([data[i],cate[i]])\n",
    "    elif 'B-sym' in cate[i]:\n",
    "        sym.append([data[i],cate[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "560e47a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dis_sym={}\n",
    "for i in dis:\n",
    "    temp=''.join(i[0])\n",
    "    all_dis_sym[temp]=i[1]\n",
    "for i in sym:\n",
    "    temp=''.join(i[0])\n",
    "    all_dis_sym[temp]=i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "dd38cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存\n",
    "filename='临时.json'\n",
    "with open(filename,'w',encoding='gbk') as file_obj:\n",
    "    json.dump(all_dis_sym,file_obj,ensure_ascii=False,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "037eee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#提取症状和病的句子模板\n",
    "sym_dis_dic={}\n",
    "for key in all_dis_sym.keys():  \n",
    "    index1=0\n",
    "    index2=-1\n",
    "    new=[]\n",
    "    temp_key=''\n",
    "    for i in range(0,len(all_dis_sym[key])):\n",
    "        if 'B-' in all_dis_sym[key][i]:\n",
    "            index1=i\n",
    "            continue\n",
    "            #flag=1\n",
    "        if 'E-' in all_dis_sym[key][i]:\n",
    "            new.extend(all_dis_sym[key][index2+1:index1])\n",
    "            temp_key=temp_key+key[index2+1:index1]+'*'\n",
    "            new.append('holder')\n",
    "            index2=i\n",
    "    new.extend(all_dis_sym[key][index2+1:])\n",
    "    temp_key=temp_key+key[index2+1:]\n",
    "    sym_dis_dic[temp_key]=new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "15bed2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='cyx_data/症状_病句子模板.json'\n",
    "with open(filename,'w',encoding='utf-8') as file_obj:\n",
    "    json.dump(sym_dis_dic,file_obj,ensure_ascii=False,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "bf7aca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dru={}\n",
    "for i in dru:\n",
    "    temp=''.join(i[0])\n",
    "    all_dru[temp]=i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "eb9a10c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#提取药的句子模板\n",
    "dru_dic={}\n",
    "for key in all_dru.keys():  \n",
    "    index1=0\n",
    "    index2=-1\n",
    "    new=[]\n",
    "    temp_key=''\n",
    "    for i in range(0,len(all_dru[key])):\n",
    "        if 'B-' in all_dru[key][i]:\n",
    "            index1=i\n",
    "            continue\n",
    "            #flag=1\n",
    "        if 'E-' in all_dru[key][i]:\n",
    "            new.extend(all_dru[key][index2+1:index1])\n",
    "            temp_key=temp_key+key[index2+1:index1]+'*'\n",
    "            new.append('holder')\n",
    "            index2=i\n",
    "    new.extend(all_dru[key][index2+1:])\n",
    "    temp_key=temp_key+key[index2+1:]\n",
    "    dru_dic[temp_key]=new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "36648384",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='cyx_data/药句子模板.json'\n",
    "with open(filename,'w',encoding='utf-8') as file_obj:\n",
    "    json.dump(dru_dic,file_obj,ensure_ascii=False,indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db15a9c",
   "metadata": {},
   "source": [
    "## 提取所有症状数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "033fd454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取json中爬取的数据\n",
    "import json\n",
    "with open('herb_extraction.json',encoding=\"gbk\") as file_obj:\n",
    "    dic=json.load(file_obj)\n",
    "    \n",
    "sym_dis=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "57cd2600",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in dic:\n",
    "    if '主治' in dic[key]:\n",
    "        con=dic[key]['主治']\n",
    "        if type(con)==dict:\n",
    "            for index in con:\n",
    "                item=con[index]\n",
    "                if '症状' in item:\n",
    "                    t=[]\n",
    "                    temp=item['症状']\n",
    "                    temp=temp.strip('。')\n",
    "                    temp=temp.strip(' ')\n",
    "                    temp=temp.replace('）','')\n",
    "                    temp=temp.split('，')\n",
    "                    for i in temp:\n",
    "                        if type(i.split('（'))==list:\n",
    "                            t.extend(i.split('（'))\n",
    "                        else:\n",
    "                            t.append(i.split('（'))\n",
    "                    tt=[]\n",
    "                    for i in t:\n",
    "                        if type(i.split('、'))==list:\n",
    "                            tt.extend(i.split('、'))\n",
    "                        else:\n",
    "                            tt.append(i.split('、'))\n",
    "                    dic[key]['主治'][index]['症状']=tt\n",
    "        else:\n",
    "                    \n",
    "            for index in range(0,len(con)):\n",
    "                item=con[index]\n",
    "                if '症状' in item:\n",
    "                    t=[]\n",
    "                    temp=item['症状']\n",
    "                    temp=temp.strip('。')\n",
    "                    temp=temp.strip(' ')\n",
    "                    temp=temp.replace('）','')\n",
    "                    temp=temp.split('，')\n",
    "                    for i in temp:\n",
    "                        if type(i.split('（'))==list:\n",
    "                            t.extend(i.split('（'))\n",
    "                        else:\n",
    "                            t.append(i.split('（'))\n",
    "                    tt=[]\n",
    "                    for i in t:\n",
    "                        if type(i.split('、'))==list:\n",
    "                            tt.extend(i.split('、'))\n",
    "                        else:\n",
    "                            tt.append(i.split('、'))\n",
    "                    dic[key]['主治'][index]['症状']=tt\n",
    "        sym_dis.extend(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f1ad4c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存\n",
    "filename='本草纲目.json'\n",
    "with open(filename,'w',encoding='gbk') as file_obj:\n",
    "    json.dump(dic,file_obj,ensure_ascii=False,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "4cb902b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cyx_data/本草纲目-拆分释名.json',encoding=\"utf-8\") as file_obj:\n",
    "    herb=json.load(file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "539a260c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in herb:\n",
    "    for index in range(0,len(herb[key]['主治'])):\n",
    "        item=herb[key]['主治'][index]\n",
    "        if type(item['症状'])!=list:\n",
    "            temp=item['症状']\n",
    "            temp=temp.replace('、','，')\n",
    "            temp=temp.strip('。')\n",
    "            temp=temp.strip(' ')\n",
    "            temp=temp.replace('）','')\n",
    "            temp=temp.replace('。','，')\n",
    "            temp=temp.split('，')\n",
    "            t=[]\n",
    "            for i in temp:\n",
    "                if type(i.split('（'))==list:\n",
    "                    t.extend(i.split('（'))\n",
    "                else:\n",
    "                    t.append(i.split('（'))\n",
    "            herb[key]['主治'][index]['症状']=t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "449afec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存\n",
    "filename='本草纲目.json'\n",
    "with open(filename,'w',encoding='utf-8') as file_obj:\n",
    "    json.dump(herb,file_obj,ensure_ascii=False,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "acda49cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cyx_data/本草纲目-最终.json',encoding=\"utf-8\") as file_obj:\n",
    "    herb=json.load(file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "d88da95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_dis=[]\n",
    "for key in herb:\n",
    "    for item in herb[key]['主治']:\n",
    "        if type(item['症状'])!=list:\n",
    "            print(item['症状'])\n",
    "        sym_dis.extend(item['症状'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "35d9c40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='cyx_data/症状语料库.json'\n",
    "with open(filename,'w',encoding='utf-8') as file_obj:\n",
    "    json.dump(list(set(sym_dis)),file_obj,ensure_ascii=False,indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ff7ee1",
   "metadata": {},
   "source": [
    "# 提取所有中药数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c1695a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('C:/Users/yuki/Desktop/本草纲目-拆分子部位.json',encoding=\"utf-8\") as file_obj:\n",
    "    herb=json.load(file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "087c454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in herb:\n",
    "    temp=herb[i]['释名']\n",
    "    temp=temp.replace('亦名','，')\n",
    "    temp=temp.replace('亦称','，')\n",
    "    temp=temp.replace('又名','，')\n",
    "    temp=temp.replace('苗名','，')\n",
    "    temp=temp.replace('子名','，')\n",
    "    temp=temp.replace('。','，')\n",
    "    temp=temp.replace('、','，')\n",
    "    temp=temp.split('，')\n",
    "    insert=[]\n",
    "    if temp!=['']:\n",
    "        for item in temp:\n",
    "            if item!='':\n",
    "                insert.append(item)\n",
    "    else:\n",
    "        insert=['']\n",
    "    herb[i]['释名']=insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "1cbc6ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存\n",
    "filename='本草纲目-拆分释名.json'\n",
    "with open(filename,'w',encoding='utf-8') as file_obj:\n",
    "    json.dump(herb,file_obj,ensure_ascii=False,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c312c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('本草纲目-拆分释名.json',encoding=\"utf-8\") as file_obj:\n",
    "    herb=json.load(file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "90d4250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "herb_all=[]\n",
    "for key in herb:\n",
    "    herb_all.append(key)\n",
    "    if type(herb[key]['主治'])==dict:\n",
    "        for cate in herb[key]['主治']:\n",
    "            herb_all.append(cate)\n",
    "    if herb[key]['释名']!=['']:\n",
    "        herb_all.extend(herb[key]['释名'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75f80267",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='cyx_data/语料库/中药名语料库.json'\n",
    "with open(filename,'w',encoding='utf-8') as file_obj:\n",
    "    json.dump(list(set(herb_all)),file_obj,ensure_ascii=False,indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478ff50a",
   "metadata": {},
   "source": [
    "# 提取所有部门名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "708ce856",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cyx_data/本草纲目-最终.json',encoding=\"utf-8\") as file_obj:\n",
    "    herb=json.load(file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eae28205",
   "metadata": {},
   "outputs": [],
   "source": [
    "depart=[]\n",
    "for key in herb:\n",
    "    if '部门' in herb[key]:\n",
    "        depart.append(herb[key]['部门'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21f4b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='cyx_data/语料库/部门名语料库.json'\n",
    "with open(filename,'w',encoding='utf-8') as file_obj:\n",
    "    json.dump(list(set(depart)),file_obj,ensure_ascii=False,indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4439f4",
   "metadata": {},
   "source": [
    "# 问句库筛选与生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247d362e",
   "metadata": {},
   "source": [
    "- L1 答：方法\n",
    "- L2 答：症状\n",
    "- L3 答：释名\n",
    "- L4 答：气味\n",
    "- L5 答：子部\n",
    "- L6 答：部门"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8fda9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e69b5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cyx_data/问句库.json',encoding=\"utf-8\") as file_obj:\n",
    "    L1=json.load(file_obj)\n",
    "l1=[]\n",
    "for i in L1:\n",
    "    l1.append(i)\n",
    "    \n",
    "for i in range(0,len(l1)):\n",
    "    l1[i]=l1[i].replace('*','')\n",
    "    while l1[i][0]=='，':\n",
    "        l1[i]=l1[i][1:]\n",
    "    while l1[i][0]=='。':\n",
    "        l1[i]=l1[i][1:]\n",
    "    while l1[i][-1]=='。':\n",
    "        l1[i]=l1[i][:-1]\n",
    "    while l1[i][-1]=='，':\n",
    "        l1[i]=l1[i][:-1]\n",
    "        \n",
    "l1=list(set(l1))\n",
    "\n",
    "l1.append('怎么办才好')\n",
    "l1.append('应该怎么办')\n",
    "l1.append('吃啥比较有效')\n",
    "l1.append('服用啥比较好')\n",
    "l1.append('吃啥比较管用')\n",
    "l1.append('该做点什么')\n",
    "l1.append('做点什么比较好')\n",
    "l1.append('应该做点什么')\n",
    "l1.append('怎么可以治好')\n",
    "l1.append('怎么治')\n",
    "l1.append('我最近老是')\n",
    "l1.append('我最近老是怎么办')\n",
    "l1.append('我最近老是，，怎么办')\n",
    "l1.append('怎么办，，我最近老是')\n",
    "\n",
    "l1=list(set(l1))\n",
    "\n",
    "filename='cyx_data/问句库/L1类_回答方法.txt'\n",
    "with open(filename,'w',encoding='utf-8') as file_obj:\n",
    "    json.dump((l1),file_obj,ensure_ascii=False,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86a02411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fcb87448",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cyx_data/药句子模板.json',encoding=\"utf-8\") as file_obj:\n",
    "    L2=json.load(file_obj)\n",
    "    \n",
    "l2=[]\n",
    "for i in L2:\n",
    "    l2.append(i)\n",
    "    \n",
    "for i in range(0,len(l2)):\n",
    "    l2[i]=l2[i].replace('*','')\n",
    "    while l2[i][0]=='，':\n",
    "        l2[i]=l2[i][1:]\n",
    "    while l2[i][0]=='。':\n",
    "        l2[i]=l2[i][1:]\n",
    "    while l2[i][-1]=='。':\n",
    "        l2[i]=l2[i][:-1]\n",
    "    while l2[i][-1]=='，':\n",
    "        l2[i]=l2[i][:-1]\n",
    "    \n",
    "l2=list(set(l2))\n",
    "\n",
    "l2.append('吃，干嘛的')\n",
    "l2.append('吃，能治什么')\n",
    "l2.append('能治什么')\n",
    "l2.append('可以治疗什么')\n",
    "l2.append('对治什么有用')\n",
    "l2.append('治疗什么症状')\n",
    "l2.append('能治什么，吃')\n",
    "l2.append('功效是什么')\n",
    "l2.append('对治什么病有用')\n",
    "l2.append('可以治什么病')\n",
    "l2.append('可以治疗什么病')\n",
    "l2.append('有什么用')\n",
    "l2.append('服用，干嘛的')\n",
    "l2.append('服用，能治什么')\n",
    "l2.append('能治什么，服用')\n",
    "\n",
    "l2=list(set(l2))\n",
    "\n",
    "filename='cyx_data/问句库/L2类_回答症状.txt'\n",
    "with open(filename,'w',encoding='utf-8') as file_obj:\n",
    "    json.dump((l2),file_obj,ensure_ascii=False,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e2d2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe4b958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l3=[]\n",
    "l3.append('叫什么')\n",
    "l3.append('还可以怎么叫')\n",
    "l3.append('还有别的名字吗')\n",
    "l3.append('还有别的称法吗')\n",
    "l3.append('还有别的称呼吗')\n",
    "l3.append('还有别的叫法吗')\n",
    "l3.append('还有其他名字吗')\n",
    "l3.append('还有其他称法吗')\n",
    "l3.append('还有其他称呼吗')\n",
    "l3.append('还有其他叫法吗')\n",
    "l3.append('还有没有别的名字')\n",
    "l3.append('还有没有别的称法')\n",
    "l3.append('还有没有别的称呼')\n",
    "l3.append('还有没有别的叫法')\n",
    "l3.append('还有没有其他名字')\n",
    "l3.append('还有没有其他称法')\n",
    "l3.append('还有没有其他称呼')\n",
    "l3.append('还有没有其他叫法')\n",
    "l3.append('又名什么')\n",
    "l3.append('又名是什么')\n",
    "l3.append('可以叫什么')\n",
    "l3.append('可以叫什么名字')\n",
    "l3.append('可以叫什么称法')\n",
    "l3.append('可以叫什么称呼')\n",
    "l3.append('可以叫什么其他名字')\n",
    "l3.append('可以叫什么其他称法')\n",
    "l3.append('可以叫什么其他称呼')\n",
    "l3.append('释名是什么')\n",
    "l3.append('其他名称是什么')\n",
    "l3.append('其他称法是什么')\n",
    "l3.append('其他名字是什么')\n",
    "l3.append('其他叫法是什么')\n",
    "l3.append('有没有其他名字')\n",
    "l3.append('有没有其他称法')\n",
    "l3.append('有没有其他称呼')\n",
    "l3.append('有没有其他叫法')\n",
    "\n",
    "l3=list(set(l3))\n",
    "\n",
    "filename='cyx_data/问句库/L3类_回答释名.txt'\n",
    "with open(filename,'w',encoding='utf-8') as file_obj:\n",
    "    json.dump((l3),file_obj,ensure_ascii=False,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa8f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#多实体分类\n",
    "xx可以治xxx吗\n",
    "xx对xxx有用吗\n",
    "我xxx，可以吃xx吗\n",
    "吃了xx，xxx还没好怎么办\n",
    "xx是xx吗\n",
    "xx和xx是同一个东西吗\n",
    "xx除了xx还有别的名字吗\n",
    "xx除了xxx还可以治疗别的症状吗\n",
    "xxx的气味是xxx吗"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4de535",
   "metadata": {},
   "source": [
    "# 问句分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99998b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import json\n",
    "from joblib import dump, load\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b33ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import random\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc529f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_question(question_path,stop_words_path):\n",
    "    #question_path='cyx_data/问句库/'\n",
    "    #stop_words_path='cn_stopwords.txt'\n",
    "    data=[]\n",
    "    label=[]\n",
    "    path=['L1类_回答方法.txt','L2类_回答症状.txt','L3类_回答释名.txt','L4类_回答气味.txt','L5类_回答子部.txt','L6类_回答部门.txt']\n",
    "    labels=[1,2,3,4,5,6]\n",
    "    for index in range(0,len(path)):\n",
    "        p=path[index]\n",
    "        print(p)\n",
    "        with open(question_path+p,encoding=\"utf-8\") as file_obj:\n",
    "            temp=json.load(file_obj)\n",
    "            \n",
    "        for item in temp:\n",
    "            text_with_space=''\n",
    "            temp_cut=jieba.cut(item)\n",
    "            for word in temp_cut:\n",
    "                text_with_space+=word+' '\n",
    "            data.append(text_with_space)\n",
    "            label.append(labels[index])\n",
    "    \n",
    "    stop_words = open(stop_words_path, 'r', encoding='utf-8').read()\n",
    "    stop_words = stop_words.encode('utf-8').decode('utf-8-sig') # 列表头部\\ufeff处理\n",
    "    stop_words = stop_words.split('\\n') # 根据分隔符分隔\n",
    "    \n",
    "    # 计算单词权重\n",
    "    tf = TfidfVectorizer(stop_words, max_df=0.5)\n",
    "    #切分测试集和训练集\n",
    "    data_all=[]\n",
    "    for i in range(0,len(data)):\n",
    "        data_all.append([data[i],label[i]])\n",
    "    random.shuffle(data_all)#打乱\n",
    "    data=[]\n",
    "    label=[]\n",
    "    for item in data_all:\n",
    "        data.append(item[0])\n",
    "        label.append(item[1])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.25, random_state=0)#随机选择25%作为测试集，剩余作为训练集\n",
    "    \n",
    "    \n",
    "    train_features = tf.fit_transform(X_train)\n",
    "    test_features = tf.transform(X_test)\n",
    "    \n",
    "    clf = MultinomialNB(alpha=0.001).fit(train_features, y_train)\n",
    "    dump(clf,'output/NBmodel.joblib')\n",
    "    dump(tf,'output/tf-idf.joblib')\n",
    "    return tf,clf,test_features,train_features,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b3c5295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\yuki\\AppData\\Local\\Temp\\jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1类_回答方法.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 3.109 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass input=['$', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '?', '_', '“', '”', '、', '。', '《', '》', '一', '一些', '一何', '一切', '一则', '一方面', '一旦', '一来', '一样', '一般', '一转眼', '万一', '上', '上下', '下', '不', '不仅', '不但', '不光', '不单', '不只', '不外乎', '不如', '不妨', '不尽', '不尽然', '不得', '不怕', '不惟', '不成', '不拘', '不料', '不是', '不比', '不然', '不特', '不独', '不管', '不至于', '不若', '不论', '不过', '不问', '与', '与其', '与其说', '与否', '与此同时', '且', '且不说', '且说', '两者', '个', '个别', '临', '为', '为了', '为什么', '为何', '为止', '为此', '为着', '乃', '乃至', '乃至于', '么', '之', '之一', '之所以', '之类', '乌乎', '乎', '乘', '也', '也好', '也罢', '了', '二来', '于', '于是', '于是乎', '云云', '云尔', '些', '亦', '人', '人们', '人家', '什么', '什么样', '今', '介于', '仍', '仍旧', '从', '从此', '从而', '他', '他人', '他们', '以', '以上', '以为', '以便', '以免', '以及', '以故', '以期', '以来', '以至', '以至于', '以致', '们', '任', '任何', '任凭', '似的', '但', '但凡', '但是', '何', '何以', '何况', '何处', '何时', '余外', '作为', '你', '你们', '使', '使得', '例如', '依', '依据', '依照', '便于', '俺', '俺们', '倘', '倘使', '倘或', '倘然', '倘若', '借', '假使', '假如', '假若', '傥然', '像', '儿', '先不先', '光是', '全体', '全部', '兮', '关于', '其', '其一', '其中', '其二', '其他', '其余', '其它', '其次', '具体地说', '具体说来', '兼之', '内', '再', '再其次', '再则', '再有', '再者', '再者说', '再说', '冒', '冲', '况且', '几', '几时', '凡', '凡是', '凭', '凭借', '出于', '出来', '分别', '则', '则甚', '别', '别人', '别处', '别是', '别的', '别管', '别说', '到', '前后', '前此', '前者', '加之', '加以', '即', '即令', '即使', '即便', '即如', '即或', '即若', '却', '去', '又', '又及', '及', '及其', '及至', '反之', '反而', '反过来', '反过来说', '受到', '另', '另一方面', '另外', '另悉', '只', '只当', '只怕', '只是', '只有', '只消', '只要', '只限', '叫', '叮咚', '可', '可以', '可是', '可见', '各', '各个', '各位', '各种', '各自', '同', '同时', '后', '后者', '向', '向使', '向着', '吓', '吗', '否则', '吧', '吧哒', '吱', '呀', '呃', '呕', '呗', '呜', '呜呼', '呢', '呵', '呵呵', '呸', '呼哧', '咋', '和', '咚', '咦', '咧', '咱', '咱们', '咳', '哇', '哈', '哈哈', '哉', '哎', '哎呀', '哎哟', '哗', '哟', '哦', '哩', '哪', '哪个', '哪些', '哪儿', '哪天', '哪年', '哪怕', '哪样', '哪边', '哪里', '哼', '哼唷', '唉', '唯有', '啊', '啐', '啥', '啦', '啪达', '啷当', '喂', '喏', '喔唷', '喽', '嗡', '嗡嗡', '嗬', '嗯', '嗳', '嘎', '嘎登', '嘘', '嘛', '嘻', '嘿', '嘿嘿', '因', '因为', '因了', '因此', '因着', '因而', '固然', '在', '在下', '在于', '地', '基于', '处在', '多', '多么', '多少', '大', '大家', '她', '她们', '好', '如', '如上', '如上所述', '如下', '如何', '如其', '如同', '如是', '如果', '如此', '如若', '始而', '孰料', '孰知', '宁', '宁可', '宁愿', '宁肯', '它', '它们', '对', '对于', '对待', '对方', '对比', '将', '小', '尔', '尔后', '尔尔', '尚且', '就', '就是', '就是了', '就是说', '就算', '就要', '尽', '尽管', '尽管如此', '岂但', '己', '已', '已矣', '巴', '巴巴', '并', '并且', '并非', '庶乎', '庶几', '开外', '开始', '归', '归齐', '当', '当地', '当然', '当着', '彼', '彼时', '彼此', '往', '待', '很', '得', '得了', '怎', '怎么', '怎么办', '怎么样', '怎奈', '怎样', '总之', '总的来看', '总的来说', '总的说来', '总而言之', '恰恰相反', '您', '惟其', '慢说', '我', '我们', '或', '或则', '或是', '或曰', '或者', '截至', '所', '所以', '所在', '所幸', '所有', '才', '才能', '打', '打从', '把', '抑或', '拿', '按', '按照', '换句话说', '换言之', '据', '据此', '接着', '故', '故此', '故而', '旁人', '无', '无宁', '无论', '既', '既往', '既是', '既然', '时候', '是', '是以', '是的', '曾', '替', '替代', '最', '有', '有些', '有关', '有及', '有时', '有的', '望', '朝', '朝着', '本', '本人', '本地', '本着', '本身', '来', '来着', '来自', '来说', '极了', '果然', '果真', '某', '某个', '某些', '某某', '根据', '欤', '正值', '正如', '正巧', '正是', '此', '此地', '此处', '此外', '此时', '此次', '此间', '毋宁', '每', '每当', '比', '比及', '比如', '比方', '没奈何', '沿', '沿着', '漫说', '焉', '然则', '然后', '然而', '照', '照着', '犹且', '犹自', '甚且', '甚么', '甚或', '甚而', '甚至', '甚至于', '用', '用来', '由', '由于', '由是', '由此', '由此可见', '的', '的确', '的话', '直到', '相对而言', '省得', '看', '眨眼', '着', '着呢', '矣', '矣乎', '矣哉', '离', '竟而', '第', '等', '等到', '等等', '简言之', '管', '类如', '紧接着', '纵', '纵令', '纵使', '纵然', '经', '经过', '结果', '给', '继之', '继后', '继而', '综上所述', '罢了', '者', '而', '而且', '而况', '而后', '而外', '而已', '而是', '而言', '能', '能否', '腾', '自', '自个儿', '自从', '自各儿', '自后', '自家', '自己', '自打', '自身', '至', '至于', '至今', '至若', '致', '般的', '若', '若夫', '若是', '若果 ', '若非', '莫不然', '莫如', '莫若', '虽', '虽则', '虽然', '虽说', '被', '要', '要不', '要不是', '要不然', '要么', '要是', '譬喻', '譬如', '让', '许多', '论', '设使', '设或', '设若', '诚如', '诚然', '该', '说来', '诸', '诸位', '诸如', '谁', '谁人', '谁料', '谁知', '贼死', '赖以', '赶', '起', '起见', '趁', '趁着', '越是', '距', '跟', '较', '较之', '边', '过', '还', '还是', '还有', '还要', '这', '这一来', '这个', '这么', '这么些', '这么样', '这么点儿', '这些', '这会儿', '这儿', '这就是说', '这时', '这样', '这次', '这般', '这边', '这里', '进而', '连', '连同', '逐步', '通过', '遵循', '遵照', '那', '那个', '那么', '那么些', '那么样', '那些', '那会儿', '那儿', '那时', '那样', '那般', '那边', '那里', '都', '鄙人', '鉴于', '针对', '阿', '除', '除了', '除外', '除开', '除此之外', '除非', '随', '随后', '随时', '随着', '难道说', '非但', '非徒', '非特', '非独', '靠', '顺', '顺着', '首先', '！', '，', '：', '；', '？', ''] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2类_回答症状.txt\n",
      "L3类_回答释名.txt\n",
      "L4类_回答气味.txt\n",
      "L5类_回答子部.txt\n",
      "L6类_回答部门.txt\n"
     ]
    }
   ],
   "source": [
    "tf,clf,test_features,train_features,test_label=train_question('cyx_data/问句库/','cn_stopwords.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3025ef1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率为： 0.9397590361445783\n"
     ]
    }
   ],
   "source": [
    "# 多项式贝叶斯分类器\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "predicted_labels = clf.predict(test_features)\n",
    "\n",
    "# 计算准确率\n",
    "print('准确率为：', metrics.accuracy_score(test_label, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc7bd2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a736cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_question(test_word,model_path,tf_path):\n",
    "    #model_path='output/NBmodel.joblib'\n",
    "    #tf_path='output/tf-idf.joblib'\n",
    "    test_temp=jieba.cut(test_word)\n",
    "    tt=''\n",
    "    for word in test_temp:\n",
    "        tt+=word+' '\n",
    "    tf=load(tf_path)\n",
    "    test_features = tf.transform([tt])\n",
    "    model=load(model_path)\n",
    "    label=model.predict(test_features)[0]\n",
    "    #['L1类_回答方法.txt','L2类_回答症状.txt','L3类_回答释名.txt','L4类_回答气味.txt','L5类_回答子部.txt','L6类_回答部门.txt']\n",
    "    if label==1:\n",
    "        return('L1')\n",
    "    elif label==2:\n",
    "        return('L2')\n",
    "    elif label==3:\n",
    "        return('L3')\n",
    "    elif label==4:\n",
    "        return('L4')\n",
    "    elif label==5:\n",
    "        return('L5')\n",
    "    elif label==6:\n",
    "        return('L6')\n",
    "    else:\n",
    "        return(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09748f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L6'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_question('草部有哪些中药','output/NBmodel.joblib','output/tf-idf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7aea2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37e3719f",
   "metadata": {},
   "source": [
    "# 随机生成语料数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "22c3272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "897d4c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cyx_data/语料库/症状语料库.json',encoding=\"utf-8\") as file_obj:\n",
    "    sym=json.load(file_obj)\n",
    "with open('cyx_data/语料库/中药名语料库.json',encoding=\"utf-8\") as file_obj:\n",
    "    dru=json.load(file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "afd0fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cyx_data/语料库/部门名语料库.json',encoding=\"utf-8\") as file_obj:\n",
    "    depar=json.load(file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "58c66378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5035"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym.index('空')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "68278d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sym[5035]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "133ae7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sym[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cbf8524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#l1和l2按照提前标注好命名实体识别的 问句库和药句子模板来生成\n",
    "with open('cyx_data/症状_病句子模板.json',encoding=\"utf-8\") as file_obj:\n",
    "    l1=json.load(file_obj)\n",
    "with open('cyx_data/药句子模板.json',encoding=\"utf-8\") as file_obj:\n",
    "    l2=json.load(file_obj)\n",
    "with open('cyx_data/问句库/L3类_回答释名.txt',encoding=\"utf-8\") as file_obj:\n",
    "    l3=json.load(file_obj)\n",
    "with open('cyx_data/问句库/L4类_回答气味.txt',encoding=\"utf-8\") as file_obj:\n",
    "    l4=json.load(file_obj)\n",
    "with open('cyx_data/问句库/L5类_回答子部.txt',encoding=\"utf-8\") as file_obj:\n",
    "    l5=json.load(file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bab6051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cyx_data/问句库/L6类_回答部门.txt',encoding=\"utf-8\") as file_obj:\n",
    "    l6=json.load(file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7815a737",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in l1:\n",
    "    if len(key)!=len(l1[key]):\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7dfc5b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#按照字标上命名实体识别的符号\n",
    "l3_dic={}\n",
    "for i in l3:\n",
    "    temp=['O']*len(i)\n",
    "    strr=i+'，'+'*'\n",
    "    temp.append('O')\n",
    "    temp.append('holder')\n",
    "    l3_dic[strr]=temp\n",
    "    \n",
    "    temp=['O']*len(i)\n",
    "    strr='*'+i\n",
    "    temp=['holder']+temp\n",
    "    l3_dic[strr]=temp\n",
    "    \n",
    "l4_dic={}\n",
    "for i in l4:\n",
    "    temp=['O']*len(i)\n",
    "    strr=i+'，'+'*'\n",
    "    temp.append('O')\n",
    "    temp.append('holder')\n",
    "    l4_dic[strr]=temp\n",
    "    \n",
    "    temp=['O']*len(i)\n",
    "    strr='*'+i\n",
    "    temp=['holder']+temp\n",
    "    l4_dic[strr]=temp\n",
    "    \n",
    "l5_dic={}\n",
    "for i in l5:\n",
    "    temp=['O']*len(i)\n",
    "    strr=i+'，'+'*'\n",
    "    temp.append('O')\n",
    "    temp.append('holder')\n",
    "    l5_dic[strr]=temp\n",
    "    \n",
    "    temp=['O']*len(i)\n",
    "    strr='*'+i\n",
    "    temp=['holder']+temp\n",
    "    l5_dic[strr]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5f734bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "l6_dic={}\n",
    "for i in l6:\n",
    "    temp=['O']*len(i)\n",
    "    strr=i+'，'+'*'\n",
    "    temp.append('O')\n",
    "    temp.append('holder')\n",
    "    l6_dic[strr]=temp\n",
    "    \n",
    "    temp=['O']*len(i)\n",
    "    strr='*'+i\n",
    "    temp=['holder']+temp\n",
    "    l6_dic[strr]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "589fbcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_dic=l1\n",
    "l2_dic=l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9ad1e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sym=len(sym)-1\n",
    "random_dru=len(dru)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f2e57129",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_depar=len(depar)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c77fee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1={}\n",
    "flag=0\n",
    "while flag<30:\n",
    "    for i in l1_dic:\n",
    "        count=i.count('*')\n",
    "        num=random.sample(range(0,random_sym),count)\n",
    "        value=l1_dic[i]\n",
    "        key=i\n",
    "        for re in num:\n",
    "            index=key.index('*')\n",
    "            key=key[:index]+sym[re]+key[index+1:]\n",
    "            if len(sym[re])==1:\n",
    "                print('a')\n",
    "                #value=value[:index]+['S']+value[index+1:]\n",
    "            else:\n",
    "                value=value[:index]+['B-sym']+['I-sym']*(len(sym[re])-2)+['E-sym']+value[index+1:]\n",
    "        L1[key]=value\n",
    "    flag+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "14ee4048",
   "metadata": {},
   "outputs": [],
   "source": [
    "L2={}\n",
    "flag=0\n",
    "while flag<30:\n",
    "    for i in l2_dic:\n",
    "        count=i.count('*')\n",
    "        num=random.sample(range(0,random_dru),count)\n",
    "        value=l2_dic[i]\n",
    "        key=i\n",
    "        for re in num:\n",
    "            index=key.index('*')\n",
    "            key=key[:index]+dru[re]+key[index+1:]\n",
    "            if len(dru[re])==1:\n",
    "                value=value[:index]+['S']+value[index+1:]\n",
    "            else:\n",
    "                value=value[:index]+['B-dru']+['I-dru']*(len(dru[re])-2)+['E-dru']+value[index+1:]\n",
    "        L2[key]=value\n",
    "    flag+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "101fcea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "L3={}\n",
    "flag=0\n",
    "while flag<30:\n",
    "    for i in l3_dic:\n",
    "        count=i.count('*')\n",
    "        num=random.sample(range(0,random_dru),count)\n",
    "        value=l3_dic[i]\n",
    "        key=i\n",
    "        for re in num:\n",
    "            index=key.index('*')\n",
    "            key=key[:index]+dru[re]+key[index+1:]\n",
    "            if len(dru[re])==1:\n",
    "                value=value[:index]+['S']+value[index+1:]\n",
    "            else:\n",
    "                value=value[:index]+['B-dru']+['I-dru']*(len(dru[re])-2)+['E-dru']+value[index+1:]\n",
    "        L3[key]=value\n",
    "    flag+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "31585044",
   "metadata": {},
   "outputs": [],
   "source": [
    "L4={}\n",
    "flag=0\n",
    "while flag<30:\n",
    "    for i in l4_dic:\n",
    "        count=i.count('*')\n",
    "        num=random.sample(range(0,random_dru),count)\n",
    "        value=l4_dic[i]\n",
    "        key=i\n",
    "        for re in num:\n",
    "            index=key.index('*')\n",
    "            key=key[:index]+dru[re]+key[index+1:]\n",
    "            if len(dru[re])==1:\n",
    "                value=value[:index]+['S']+value[index+1:]\n",
    "            else:\n",
    "                value=value[:index]+['B-dru']+['I-dru']*(len(dru[re])-2)+['E-dru']+value[index+1:]\n",
    "        L4[key]=value\n",
    "    flag+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ea7d7f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "L5={}\n",
    "flag=0\n",
    "while flag<30:\n",
    "    for i in l5_dic:\n",
    "        count=i.count('*')\n",
    "        num=random.sample(range(0,random_dru),count)\n",
    "        value=l5_dic[i]\n",
    "        key=i\n",
    "        for re in num:\n",
    "            index=key.index('*')\n",
    "            key=key[:index]+dru[re]+key[index+1:]\n",
    "            if len(dru[re])==1:\n",
    "                value=value[:index]+['S']+value[index+1:]\n",
    "            else:\n",
    "                value=value[:index]+['B-dru']+['I-dru']*(len(dru[re])-2)+['E-dru']+value[index+1:]\n",
    "        L5[key]=value\n",
    "    flag+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e3e9687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "L6={}\n",
    "flag=0\n",
    "while flag<30:\n",
    "    for i in l6_dic:\n",
    "        count=i.count('*')\n",
    "        num=random.sample(range(0,random_depar),count)\n",
    "        value=l6_dic[i]\n",
    "        key=i\n",
    "        for re in num:\n",
    "            index=key.index('*')\n",
    "            key=key[:index]+depar[re]+key[index+1:]\n",
    "            if len(depar[re])==1:\n",
    "                value=value[:index]+['S']+value[index+1:]\n",
    "            else:\n",
    "                value=value[:index]+['B-dep']+['I-dep']*(len(depar[re])-2)+['E-dep']+value[index+1:]\n",
    "        L6[key]=value\n",
    "    flag+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "29613bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('cyx_data/训练库/train.txt',mode='w',encoding='utf-8')\n",
    "for key in L1:\n",
    "    for i in key:\n",
    "        f.write(i+' ')\n",
    "    f.write('\\n')\n",
    "    \n",
    "for key in L2:\n",
    "    for i in key:\n",
    "        f.write(i+' ')\n",
    "    f.write('\\n')\n",
    "    \n",
    "for key in L3:\n",
    "    for i in key:\n",
    "        f.write(i+' ')\n",
    "    f.write('\\n')\n",
    "    \n",
    "for key in L4:\n",
    "    for i in key:\n",
    "        f.write(i+' ')\n",
    "    f.write('\\n')\n",
    "    \n",
    "for key in L5:\n",
    "    for i in key:\n",
    "        f.write(i+' ')\n",
    "    f.write('\\n')\n",
    "    \n",
    "for key in L6:\n",
    "    for i in key:\n",
    "        f.write(i+' ')\n",
    "    f.write('\\n')\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e24e4298",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('cyx_data/训练库/train_label.txt',mode='w',encoding='utf-8')\n",
    "for key in L1:\n",
    "    con=L1[key]\n",
    "    for i in con:\n",
    "        f.write(i+' ')\n",
    "    f.write('\\n')\n",
    "    \n",
    "for key in L2:\n",
    "    con=L2[key]\n",
    "    for i in con:\n",
    "        f.write(i+' ')\n",
    "    f.write('\\n')\n",
    "    \n",
    "for key in L3:\n",
    "    con=L3[key]\n",
    "    for i in con:\n",
    "        f.write(i+' ')\n",
    "    f.write('\\n')\n",
    "    \n",
    "for key in L4:\n",
    "    con=L4[key]\n",
    "    for i in con:\n",
    "        f.write(i+' ')\n",
    "    f.write('\\n')\n",
    "    \n",
    "for key in L5:\n",
    "    con=L5[key]\n",
    "    for i in con:\n",
    "        f.write(i+' ')\n",
    "    f.write('\\n')\n",
    "    \n",
    "for key in L6:\n",
    "    con=L6[key]\n",
    "    for i in con:\n",
    "        f.write(i+' ')\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
